---
title: "Assignment2"
output: html_document
---
```{r setup, include=FALSE}
knitr::opts_chunk$set(
  message    = FALSE,   
  warning    = FALSE,   
  fig.align  = "center",
  fig.width  = 4.5,       
  fig.height = 3,
  dpi        = 120,
  out.width  = "70%",   
  fig.show   = "hold"   
)
```

```{r, include=FALSE}
# Clear plots
if(!is.null(dev.list())) dev.off()

# Clean workspace
rm(list=ls())
```

# 1. Data preparation

The first step is to check the dataset, to understand which variables we can work with, and set their datatypes accordingly.

```{r}
# Loading data
df <- read.csv("aug_train.csv", header=T)
summary(df)
```
We will set the datatypes accordingly.

After checking the dataset, we observe that many variable's observations are left in blank, we set them to NA because they are missing data.

```{r}
# Converting characters to factor
df[sapply(df, is.character)] <- lapply(df[sapply(df, is.character)], as.factor)

# Converting binary columns (only 0 or 1) to factor
df[sapply(df, function(x) all(na.omit(unique(x)) %in% c(0, 1)))] <- 
  lapply(df[sapply(df, function(x) all(na.omit(unique(x)) %in% c(0, 1)))], as.factor)

# Setting NAs
df[df == ""] <- NA
summary(df)
str(df)
```

After a first inspection, we have decided to remove `enrollee_id`and `city` from our working dataset, given that `enrollee_id` is an unnecessary id for each observation (after checking that there are no duplicates) and that `city` is a factor with a very high number of levels (123), whose information is contained in the `city_development_index` variable, as can be seen by the distinct combination of `city` and `city_development_index`.

We confirm that `enrollee_id` does not have duplicates or missing data, as we wanted, because it's the variable that identifies each enrollee. But this variable is not necessary for modelling because it doesn't have predictive power, so we remove it.

```{r}
# Duplicates and missing values for enrollee_id
sum(duplicated(df$enrollee_id))
sum(is.na(df$enrollee_id))
```

```{r}
# Distinct combination of city and city_development_index
library(dplyr)
nrow(distinct(df, df$city, df$city_development_index))
```
```{r}
# Remove city and enrollee_id variables from the dataset
df <- df[,-c(1,2)]
str(df)
```

After removing `enrollee_id` we found 60 observations that contain the same information for every variable in the dataset. Considering the background of this dataset, this could happen, as the variables characterize the profile in a general way, making it possible to have the exact same information corresponding to two different individuals. Thus, we consider the best option is not to remove these observations and retain them.

```{r}
any(duplicated(df))
sum(duplicated(df))

dup_rows <- df %>% 
  filter(duplicated(.) | duplicated(., fromLast = TRUE))

nrow(dup_rows)
```
Then, we check the missing data of the variables to see which ones are the most affected. We also check the count of missing values per individual, to see which observations are not reliable (those with a high % of missing values), to discuss whether or not to remove them. 

```{r}
# Number of missing values: Variables
check_na <- function(x) {
  na = sum(is.na(x))
  }
results <- lapply(df, check_na); results

# Number of missing values: Individuals
table(rowSums(is.na(df)))
```

After analyzing the individuals, we have observed that some of them have more than 30% missing values (missing values in more than 3 of the 12 total variables). We have to further assess this, applying imputation in those variables that seem reliable. For example, `gender` can be imputed as 'Undefined' since many people does not want to indicate their gender. Also, `company_type` NA, can be imputed as 'Undefined' and a new factor grouping the levels according to their behavior (probability of positive outcome).

After this assessment, we will check again missing values in individuals. 

For the rest of the missing values, since they don't represent a very big loss of information, we will analyze more in depth in the following sections:
  - Missingness mechanism (MCAR...)
  - Missingness per variable (some have around 30% of missing values)

## 1.1. Variable analysis
  
### Numerical variables

#### city_development_index
The variable `city_development_index` has no NA and no severe outliers, only mild outliers, but we won't remove them.

```{r}
summary(df$city_development_index)

# Outliers
varout <- summary(df$city_development_index)
iqr = varout[5]-varout[2]
usout <- varout[5]+3*iqr
lsout <- varout[2]-3*iqr
umout <- varout[5]+1.5*iqr
lmout <- varout[2]-1.5*iqr

sev_out <- which((df$city_development_index > usout) | (df$city_development_index < lsout))
mild_out <- which((df$city_development_index > umout) | (df$city_development_index < lmout))

boxplot(df$city_development_index, horizontal = T, main = "Boxplot city_development_index")
abline(v=usout,col='red', add = T)
abline(v=lsout,col='red', add = T)
abline(v=umout,col='orange', add = T)
abline(v=lmout,col='orange', add = T)
length(sev_out) #0
length(mild_out) #17

# Distribution
hist(df$city_development_index, freq = F)
m = mean(df$city_development_index)
std = sd(df$city_development_index)
curve(dnorm(x,m,std),add=T, col="red")
```

#### training_hours
The variable `training_hours` does not have any missing values.

```{r}
summary(df$training_hours)

# Outliers
varout <- summary(df$training_hours)
iqr = varout[5]-varout[2]
usout <- varout[5]+3*iqr
lsout <- varout[2]-3*iqr
umout <- varout[5]+1.5*iqr
lmout <- varout[2]-1.5*iqr

sev_out <- which((df$training_hours > usout) | (df$training_hours < lsout))
length(sev_out) #275
mild_out <- which((df$training_hours > umout) | (df$training_hours < lmout))
length(mild_out) #984

boxplot(df$training_hours, horizontal = T, main = "Boxplot training_hours")
abline(v=usout,col='red', add = T)
abline(v=lsout,col='red', add = T)
abline(v=umout,col='orange', add = T)
abline(v=lmout,col='orange', add = T)

# Distribution
hist(df$training_hours, freq = F)
m = mean(df$training_hours)
std = sd(df$training_hours)
curve(dnorm(x,m,std),add=T, col="red")
```

We see that the variable is left-skewed, so in order to properly address outlying observations, we will analyze the log-transformation of the variable.

We can see how it does not have any extreme outliers, and it has 226 mild outliers because, since it comes from a discrete numerical variable, they are overlapping on the boxplot.

```{r}
df$log_th <- log(df$training_hours)

# Outliers
varout <- summary(df$log_th)
iqr = varout[5]-varout[2]
usout <- varout[5]+3*iqr
lsout <- varout[2]-3*iqr
umout <- varout[5]+1.5*iqr
lmout <- varout[2]-1.5*iqr

sev_out <- which((df$log_th > usout) | (df$log_th < lsout)); length(sev_out) #0
mild_out <- which((df$log_th > umout) | (df$log_th < lmout)); length(mild_out) #224

boxplot(df$log_th, horizontal = T, main = "Boxplot log(training_hours)")
abline(v=usout,col='red', add = T)
abline(v=lsout,col='red', add = T)
abline(v=umout,col='orange', add = T)
abline(v=lmout,col='orange', add = T)

# Distribution
hist(df$log_th, freq = F)
m = mean(df$log_th)
std = sd(df$log_th)
curve(dnorm(x,m,std),add=T, col="red")
which(df$log_th == 0)
```

We have decided to create a factor in order to check in the modelling stages whether the numerical variable or the factor is better for the model.

```{r}
df$f.training <- cut(
  df$training_hour,
  breaks = quantile(df$training_hour, probs = seq(0,1,0.2), na.rm=TRUE),
  include.lowest = TRUE)

barplot(table(df$f.training), main = "Barplot of f.training", col="lightblue")
summary(df$f.training)
```


### Categorical variables

#### target
The variable `target` is a binary variable that defines the positive or negative outcome of the prediction. It has no missing data, and it is clearly unbalanced, which should be taken into account in the modelling stage.

```{r}
sum(is.na(df$target))
table(df$target)

barplot(table(df$target), main = "Barplot of target", col="lightblue")
```

#### gender
The variable `gender` has 4508 missing values, apart from the categories 'Female', 'Male' and 'Other'. Because many people might simply choose not to indicate their gender, we decided to treat these NAs as a meaningful response rather than as missing data. For this reason, all NA values are assigned into a new category called 'Undefined', which is different from 'Other' and only reflects the absence of a stated gender. After this, the variable has no remaining missing values.

```{r}
sum(is.na(df$gender))
table(df$gender)

barplot(table(df$gender), main = "Barplot of gender", col="lightblue")
```

```{r}
# Define new category 'Undefined'
df$gender <- as.character(df$gender)        
df$gender[is.na(df$gender)] <- "Undefined"
df$gender <- factor(df$gender)     

sum(is.na(df$gender))
table(df$gender)
barplot(table(df$gender), main = "Barplot of gender", col="lightblue")
```

#### relevent_experience
The variable `relevent_experience` does not have missing data and it has 2 levels: 'Has relevant experience' and 'No relevant experience', which we rename to 'Yes' and 'No'.

```{r}
sum(is.na(df$relevent_experience))
table(df$relevent_experience)

# Rename categories
df$relevent_experience <- factor(df$relevent_experience,
                                 levels = c("Has relevent experience", "No relevent experience"),
                                 labels = c("Yes", "No"))

barplot(table(df$relevent_experience), main = "Barplot of relevent_experience", col="lightblue")
```

#### enrolled_university
The variable `enrolled_university` contains 386 missing values and 3 levels: 'Full time course', 'no_enrollment' and 'Part time course'. Since the purpose of this variable is to indicate whether the person is currently studying, it is reasonable to assume that missing values refer to individuals who are not enrolled in any course. For this reason, we assign all NA values into the 'no_enrollment' category. After this, the variable has no remaining missing values. !!!!

```{r}
sum(is.na(df$enrolled_university))
table(df$enrolled_university)

barplot(table(df$enrolled_university), main = "Barplot of enrolled_university", col="lightblue")
```

```{r}
# DE MOMENT NAs ELS HE DEFINIT COM no_enrollment!! mirar si ok o no
# Assign missing values to 'no_enrollment'
df$enrolled_university <- as.character(df$enrolled_university)        
df$enrolled_university[is.na(df$enrolled_university)] <- "no_enrollment"
df$enrolled_university <- factor(df$enrolled_university)     

sum(is.na(df$enrolled_university))
table(df$enrolled_university)
barplot(table(df$enrolled_university), main = "Barplot of enrolled_university", col="lightblue")
```

#### education_level
The variable `education_level` has 460 NA and 5 levels: 'Graduate', 'High School', 'Masters', 'Phd' and 'Primary School'. Since we cannot reliably assign these missing values to any of the existing levels, we will later apply an appropriate imputation method to handle them.

```{r}
sum(is.na(df$education_level))
table(df$education_level)

barplot(table(df$education_level), main = "Barplot of education_level", col="lightblue")
```

#### major_discipline
The variable `major_discipline` contains 2813 missing values and 6 levels: 'Arts', 'Business Degree', 'Humanities', 'No major', 'STEM' and 'Other'.

To understand why so many values are missing, we compare this variable with the information from `education_level`. This shows that all individuals with 'High School' and 'Primary School' education have NA in `major_discipline` simply because a major is not applicable at these levels. Therefore, the only truly missing cases are those from participants with 'Graduate' or 'Masters' education.

```{r}
sum(is.na(df$major_discipline))
table(df$major_discipline)

barplot(table(df$major_discipline), main = "Barplot of major_discipline", col="lightblue")
```

```{r}
# Compare major_discipline with education_level
table(df$education_level[is.na(df$major_discipline)])
table(df$education_level)
```

Since the original distribution of majors is highly unbalanced, with 'STEM' being the dominant category, we decide to recode this variable into 3 groups: 'STEM', 'Non-STEM' and 'No major'. The 'Non-STEM' category includes 'Arts', 'Business Degree', 'Humanities' and 'Other'. The 'No major' group is kept for individuals who report “No major” despite holding a higher-education degree, since we have no reliable way to determine whether they belong to 'STEM' or 'Non-STEM'.

After grouping the categories, 711 values remain missing. These NAs correspond to individuals who should have a declared major but did not report it. We will use a suitable imputation method.

```{r}
library(dplyr)

df$major_discipline <- as.character(df$major_discipline)

df$major_discipline <- dplyr::case_when(
  df$education_level %in% c("High School", "Primary School") ~ "No major",
  df$major_discipline == "STEM" ~ "STEM",
  df$major_discipline %in% c("Other", "Arts", "Business Degree", "Humanities") ~ "Non-STEM"
)

df$major_discipline <- factor(df$major_discipline,
                                  levels = c("STEM", "Non-STEM", "No major"))

# Check after grouping
sum(is.na(df$major_discipline)) # 711 NAs
table(df$major_discipline)
barplot(table(df$major_discipline), main = "Barplot of major_discipline grouped", col="lightblue")
```

#### experience
The variable `experience` has 65 missing values and originally includes 23 different levels, ranging from '<1' to '>20' years. 

Following the recommended approach for truncated data, we first convert the variable into a numeric format by replacing <1 with 0.1 and >20 with 25. We then create a second version of the variable (`f.experience`) by grouping the numeric values into broader and more interpretable career stages: 'Junior', 'Early', 'Mid', 'Senior' and '>20'.

```{r}
sum(is.na(df$experience))
length(unique(df$experience)) # check number of unique categories
table(df$experience)

barplot(table(df$experience), main = "Barplot of experience", col="lightblue")
```

```{r}
# Clean and convert experience to numeric
exp_num <- df$experience
exp_num <- gsub("<1", "0.1", exp_num)
exp_num <- gsub(">20", "25", exp_num)

df$experience <- as.numeric(exp_num)
```

```{r}
# Group numeric values: f.experience
df$f.experience <- cut(
  df$experience,
  breaks = c(-1, 2, 5, 10, 19, Inf),
  labels = c("Junior", "Early", "Mid", "Senior", ">20")
)

# Check after grouping
sum(is.na(df$f.experience))
table(df$f.experience)
barplot(table(df$f.experience), main = "Barplot of experience grouped", col="lightblue")
```

After checking the profile of the 65 missing values, we observe that most of them come from individuals with higher education levels (Graduate, Masters or PhD), for whom work experience should be known. Therefore, these are considered genuine missing cases rather than “no experience”, and we will impute them later using an appropriate multivariate imputation method.

```{r}
table(df$education_level[is.na(df$experience)])
table(df$enrolled_university[is.na(df$experience)])
```

#### company_size
The variable `company_size` contains 5938 missing values and 8 original categories. Since it cannot be meaningfully treated as a numeric variable, we group the existing levels into more interpretable categories. We merge the <10, 10/49 and 50-99 groups into a single 'Small' category, define 'Medium', 'Large', and 'Very large' as the remaining size brackets, and assign missing values to an additional category labelled 'Undefined'. This simplified version of the variable is easier to interpret.

```{r}
sum(is.na(df$company_size))
length(unique(df$company_size)) #check number of unique categories
table(df$company_size)

barplot(table(df$company_size), main = "Barplot of company_size", col="lightblue")
```
```{r}
# Discretize company_size
df$company_size <- dplyr::case_when(
  df$company_size %in% c("<10", "10/49", "50-99") ~ "Small",
  df$company_size %in% c("100-500", "500-999") ~ "Medium",
  df$company_size == "1000-4999" ~ "Large",
  df$company_size %in% c("5000-9999", "10000+") ~ "Very large",
  is.na(df$company_size) ~ "Undefined"
)

df$company_size <- factor(
  df$company_size,
  levels = c("Small", "Medium", "Large", "Very large", "Undefined"))

# Check after grouping
sum(is.na(df$company_size))
table(df$company_size)
barplot(table(df$company_size), main = "Barplot of company_size discretized", col="lightblue")
```

#### company_type
The variable `company_type` contains 6140 missing values and 6 categories. Since the distribution is highly imbalanced, we group the different types of companies into broader categories: 'Private', 'Public', 'Startup' and 'Other'. Following the same criteria used in previous variables, we assign all missing values to an additional category labelled 'Undefined', as they likely correspond to respondents who did not report or did not know the company type. 

```{r}
sum(is.na(df$company_type))
length(unique(df$company_type)) #check number of unique categories
table(df$company_type)

barplot(table(df$company_type), main = "Barplot of company_type", col="lightblue")
```

```{r}
# Group levels of company_size and assign "Undefined" to NAs
df$company_type <- dplyr::case_when(
  df$company_type == "Pvt Ltd" ~ "Private",
  df$company_type == "Public Sector" ~ "Public",
  df$company_type %in% c("Early Stage Startup", "Funded Startup") ~ "Startup",
  df$company_type %in% c("NGO", "Other") ~ "Other",
  is.na(df$company_type) ~ "Undefined"
)

df$company_type <- factor(
  df$company_type,
  levels = c("Private", "Public", "Startup", "Other", "Undefined")
)

# Check after grouping
sum(is.na(df$company_type))
table(df$company_type)
barplot(table(df$company_type), main = "Barplot of company_type grouped", col="lightblue")
```

#### last_new_job
The variable `last_new_job` contains 423 missing values and 6 categories. After checking the experience profile of these cases, we observe that NAs appear across all experience levels, which indicates that they correspond to genuine missing values rather than “no experience” situations. For this reason, we keep the NAs at this stage and will handle them later using an imputation method.

```{r}
sum(is.na(df$last_new_job))
length(unique(df$last_new_job)) #check number of unique categories
table(df$last_new_job)

barplot(table(df$last_new_job), main = "Barplot of last_new_job", col="lightblue")
```

```{r}
df$last_new_job <- dplyr::case_when(
  df$last_new_job %in% c("1", "2", "3") ~ df$last_new_job,
  df$last_new_job %in% c("4", ">4") ~ "4+",
  df$last_new_job == "never" ~ "never"
)

df$last_new_job <- factor(
  df$last_new_job,
  levels = c("never", "1", "2", "3", "4+"))

barplot(table(df$last_new_job), main = "Barplot of last_new_job", col="lightblue")
```


```{r}
table(df$f.experience[is.na(df$last_new_job)])
```

## 1.2. Correlation matrix

To explore potential linear dependencies among the numerical features, we computed their correlation matrix.

```{r}
dfnum <- df[,c(1, 7, 11)] # Numerical variables 
cor(dfnum, use = "complete.obs")

require(corrplot)
M <- cor(dfnum, use = "complete.obs")
par(mfrow = c(1,1))  # per si havies tocat abans
corrplot(
  M,
  method = "number",   # només números
  type   = "upper",    # només semicorrelació
  tl.col = "black",    # noms en negre
  tl.srt = 45,         # girar una mica les etiquetes
  tl.cex = 0.9,        # mida etiquetes
  number.cex = 1.2,    # números més grans
  mar = c(0,0,1,0),    # marges petits
  title = "Correlation matrix"
)
```


## 1.3. Missing values: variables and individuals

After examining each variable individually, we applied different treatments depending on the nature of the missing values. Variables such as `gender`, `company_size` and `company_type` contain NAs that reflect non-response or non-applicability, so we assign these cases to a new' 'Undefined' category. In contrast, for variables where the missing values correspond to genuinely unknown information, such as `education_level`, `major_discipline`, `experience` and `last_new_job`, we keep the NAs unchanged to later impute them.

After completing this variable-level cleaning, we now recalculate the percentage of missing values both per variable and per individual.

Specifically, `education_level` still has 460 missing values, `major_discipline` has 711, `experience` retains 65 missing values, and `last_new_job` has 423.

```{r}
# Missing values per variable
check_na <- function(x) {
  na = sum(is.na(x))
  }
results <- lapply(df, check_na); results

# Missing values per individual
table(rowSums(is.na(df)))
```
Only 12 individuals present more than 30% missing values (4 or more missing variables). Since these observations contain insufficient information to be reliably imputed, and represent a negligible portion of the dataset, we decide to remove them from the analysis.

```{r}
sum(rowSums(is.na(df)) >= 4)
df[rowSums(is.na(df)) >= 4,]
```


```{r}
# Create a variable counting the number of missing values per individual (row)
df$nb_miss <- rowSums(is.na(df))

df$nb_miss <- factor(
  cut(df$nb_miss,
      breaks = c(-1, 0, 1, 2, 3, 4, 5),
      labels = c('0', '1', '2', '3', '4' ,'5')
  ))

# Check distribution
table(df$nb_miss)
```

```{r}
# Profiling 
library(FactoMineR)

dfprof <- df[,-c(13)]
names(dfprof)

res.cat <- catdes(dfprof, which(names(dfprof) == 'nb_miss'))
res.cat$quanti.var
res.cat$test.chi2
res.cat$quanti
res.cat$category
```

```{r}
# Remove individuals with excessive missing values
df2 <- df[rowSums(is.na(df)) < 4, -c(13,15,16)]
```


## 1.4. Imputation
To address the remaining missing values in the dataset, we apply a multivariate imputation using the **MICE algorithm**. Since only the original variables contain meaningful missing information, we impute `education_level`, `major_discipline`, `experience` and `last_new_job`, while excluding any derived variables. The imputation model includes the rest of the relevant predictors. After the imputation is completed, derived variables such as `f.experience` will be recomputed from the imputed values.

```{r}
library(mice) 

# MICE imputation
vars <- c(
  "gender", "relevent_experience", "enrolled_university",
  "education_level", "major_discipline", "experience",
  "company_size", "company_type", "last_new_job",
  "city_development_index", "training_hours")

df_mice <- df2[vars]

ini  <- mice(df_mice, maxit = 0, printFlag = FALSE)
meth <- ini$method

meth["experience"]  <- "pmm"
meth["education_level"] <- "polyreg"
meth["major_discipline"]  <- "polyreg"
meth["last_new_job"]  <- "polyreg"

imp <- mice(
  df_mice,
  m = 5,
  maxit = 5,
  method = meth,
  seed = 123)

completed_df <- complete(imp)

vars_no_impute <- setdiff(names(df2), vars)
df3 <- cbind(completed_df, df2[vars_no_impute])

# #### USING MICE?
# library(mice)
# res.mice <- mice(df[c(2:8,12:13,16:18)], m = 1, maxit = 5, seed = 123)
# dfimp <-complete(res.mice)
# summary(dfimp)
# 
# # we put imputed variables back into original df
# df[, c("gender",
#        "enrolled_university",
#        "education_level",
#        "major_discipline",
#        "company_size_group",
#        "company_type_group",
#        "last_new_job")] <- cat_imputed
# 
# summary(df)
```

### Validation
To validate the imputation, we use different approaches depending on the type of variable. For numerical variables, we compare the quantiles before and after imputation to ensure that the distribution remains consistent. For categorical variables, we compare the proportion of each category before and after imputation. In both cases, the distributions remain stable, indicating that the imputation has not distorted the underlying structure of the data.

```{r}
# Numerical vars validation
quantile(df2$experience, probs=seq(0,1,by=0.1), na.rm=T)
quantile(df3$experience, probs=seq(0,1,by=0.1), na.rm=F)
```

```{r}
# Categorical vars validation
cat_vars <- c("education_level", "major_discipline", "last_new_job")

for (v in cat_vars) {
  cat("\n", v, "\n")
  
  # Proportions before
  prop_before <- prop.table(table(df2[[v]], useNA = "no"))
  
  # Proportions after
  prop_after  <- prop.table(table(df3[[v]]))
  
  cat("Before (no NA):\n")
  print(round(prop_before, 4))
  
  cat("After (imputed):\n")
  print(round(prop_after, 4))
}
```

```{r}
# Define f.experience from experience imputed
df3$f.experience <- cut(
  df3$experience,
  breaks = c(-1, 2, 5, 10, 19, Inf),
  labels = c("Junior", "Early", "Mid", "Senior", ">20")
)

# Check after grouping
sum(is.na(df3$f.experience))
table(df3$f.experience)
barplot(table(df3$f.experience), main = "Barplot of experience grouped", col="lightblue")
```


# 2. Profiling and Feature Selection

To explore how each feature relates to the target variable, we compute the `condes()` analysis. 

- For numerical variables, the strongest association is found for `city_development_index` (correlation = –0.34), indicating that candidates living in highly developed cities are less likely to join the company. The variable `experience` also shows a negative association, while `training_hours` has almost no effect.

- Among categorical features, the variables with the highest explanatory power are `company_size`, `company_type`, and `f.experience`, followed by `enrolled_university`, `relevant_experience` and `education_level`. Several categories, such as 'Undefined' in `company` characteristics or 'Junior' in `experience`, show a clear increase in the probability of the positive class, whereas more senior profiles and candidates working in medium or large companies tend to be less likely to change jobs.

```{r}
# Profiling of target variable
df3$target <- as.numeric(as.character(df3$target)) # target as numeric

res.con <- condes(df3, which(names(df3) == 'target'))
res.con$quanti
res.con$quali
res.con$category
```

# 3. Modeling using numeric variables



# 4. Residual analysis: unusual and influent data filtering




# 5. Adding factor main effects to the best model containing numeric variables





# 6. Residual analysis: unusual and influent data filtering





# 7. Adding factor main effects and interactions to the best model containing numeric variables




# 8. Final Residual analysis: unusual and influent data filtering




# 9. Goodness of fit and Model Interpretation
